import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.metrics import roc_curve, auc
import tensorflow as tf
from sklearn.linear_model import SGDClassifier
from sklearn.neighbors import  KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.preprocessing import scale   
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report

df = pd.read_csv("Malware dataset.csv")
print("shape_of_data",df.shape)
df = df.dropna(how="any",axis=0)
df["classification"].unique()
df["classification"].value_counts()
sns.countplot(df["classification"])
plt.show()

df["classification"] = df.classification.map({"malware": 0,"benign": 1})
x=df.drop(["hash","classification",'vm_truncate_count','shared_vm','exec_vm','nvcsw','maj_flt','utime'],axis=1)
y = df["classification"]
x.head()
new_data_to_be_test = x.iloc[:24,:27]
y_true = y.iloc[:24]
y.unique()

class Machine_learning_model():
    def __init__(self, model , X, y):
        self.model = model
        self.X = X
        self.y = y
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)
        print("=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>=====")
        
        self.model.fit(self.X_train,self.y_train)
        print(f"{self.model_str()} Model Trained..")
        print("")
     
    def model_str(self):
        return str(self.model.__class__.__name__)
                 
    def accuracy(self):
        y_pred = self.prediction()
        y_test = self.y_test
        
        acc = accuracy_score(y_pred, y_test)
        print(f"{self.model_str()} Model Accuracy: ", acc)
    
    def cross_validation(self, cv=5):
        
        print(f"Evaluate {self.model_str()} score by cross-validation...")
        CVS = cross_val_score(self.model, self.X_train, self.y_train, scoring='accuracy', cv=cv)
        print(CVS)
        print("="*60, "\nMean accuracy of cross-validation: ", CVS.mean())
        
    def prediction(self, test_x=None, test=False):
        if test == False:
            y_pred = self.model.predict(self.X_test)
        else:
            y_pred = self.model.predict(test_x)# if u want to test a new datasets
            
        return y_pred
    
        
    def confusionMatrix(self):        
        plt.figure(figsize=(5, 5))
        mat = confusion_matrix(self.y_test, self.prediction())
        sns.heatmap(mat.T, square=True, 
                    annot=True, 
                    cbar=False)
        
        plt.title(self.model_str() + " Confusion Matrix")
        plt.xlabel('Predicted Values')
        plt.ylabel('True Values')
        plt.show()
        
    def classificationReport(self):
        print(self.model_str() + " Classification Report" + "\n" + "="*60)
        print(classification_report(self.y_test, 
                                    self.prediction(), 
                                    target_names=['malware', 'benign']))
    
    def rocCurve(self):
        fpr, tpr = roc_curve(self.y_test, self.prediction())
        print("auc",auc(fpr, tpr))
    
    def scores_(self, cv=5):
        print(self.model_str() + "\n" + "="*60)
        
        cv_acc1 = precision_score(self.y_test,
                                   self.prediction())
        cv_acc2 = recall_score(self.y_test,
                               self.prediction())
        cv_acc3 = f1_score(self.y_test,
                               self.prediction())
        
        print(f"{self.model_str()} precision score: {cv_acc1}")
        print(f"{self.model_str()} recall score: {cv_acc2}")
        print(f"{self.model_str()} f1_score: {cv_acc3}")
        

# you can add any model here if u wish too

extra = ExtraTreesClassifier()
paras = {"n_estimators":[100,300,200],
        "max_depth":[2,3],
        "min_samples_leaf":[2,3,4],
        "criterion":["gini","entropy"],
        "min_samples_split":[2,3,4]}

extra_tun = GridSearchCV(extra,paras,n_jobs=-1,verbose=1,cv=10)

clf = SGDClassifier(random_state=43)
paras = {"penalty":["l2","l1"],
        "loss":["hinge","modified_huber"]
        }

tun_1 = GridSearchCV(clf,paras,n_jobs=-1,verbose=1,cv=10)

clf1 = XGBClassifier()

km = KNeighborsClassifier()

clf3 = GaussianNB()
boost_clf3 = AdaBoostClassifier(base_estimator=clf3,n_estimators=200,
                            learning_rate=0.001)


rd_clf = RandomForestClassifier(n_estimators=100)

paras = {"n_estimators":[50,300,100],
        "max_depth":[2,3],
        "min_samples_leaf":[2,3,4],
        "max_depth":[2,3],
        "oob_score":[True,False]}

grid_rd = GridSearchCV(rd_clf,paras,n_jobs=-1,verbose=1,cv=5)

clf4 = GradientBoostingClassifier( )

model_ = Machine_learning_model(grid_rd,x,y)
#model_.scores_()
#model_.classificationReport()
model_.accuracy()
model_.confusionMatrix()
#model_.rocCurve()
#model_.cross_validation()

new_pred = model_.prediction(test_x=new_data_to_be_test, test=True)
print(new_pred==y_true)